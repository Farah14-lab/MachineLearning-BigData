{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN5twyxsRQCmxKyV0kHYTKl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Farah14-lab/MachineLearning-BigData/blob/main/ML_BigData_Slide30.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect Google Drive Untuk Ambil Data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "gJ-dyXkv5d43",
        "outputId": "809dbe19-1ab8-4c36-8c96-e9687202c9eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install PySpark\n",
        "!pip install pyspark"
      ],
      "metadata": {
        "id": "asYRyduB5-n0",
        "outputId": "c2f3f2f7-adcc-4dd8-a5fb-beae6e9469d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.4.0)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Library\n",
        "from pyspark.sql import SparkSession, Row\n",
        "from pyspark.ml.recommendation import ALS\n",
        "from pyspark.sql.functions import col\n",
        "from pyspark.sql.types import IntegerType, FloatType, StructField, StructType\n",
        "from pyspark.ml.recommendation import ALSModel\n",
        "\n",
        "spark = SparkSession.builder.appName(\"Movie Lens\").getOrCreate()"
      ],
      "metadata": {
        "id": "3k_nZMrQheEm"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the parseRating function\n",
        "def parseRating(line):\n",
        "    if line != \"userId,movieId,rating,timestamp\":\n",
        "        fields = line.split(\",\")\n",
        "        userId = int(fields[0])\n",
        "        movieId = int(fields[1])\n",
        "        rating = float(fields[2])\n",
        "        timestamp = int(fields[3])\n",
        "        return Row(userId=userId, movieId=movieId, rating=rating, timestamp=timestamp)"
      ],
      "metadata": {
        "id": "8EvXwd3JemZr"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the file and parse the ratings\n",
        "raw = spark.sparkContext.textFile(\"/content/drive/MyDrive/BigData/ML/ratings.DAT\")\n",
        "ratings = raw.map(parseRating).filter(lambda x: x is not None)"
      ],
      "metadata": {
        "id": "lFhvBQlCiD9E"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the schema for DataFrame\n",
        "schema = StructType([\n",
        "    StructField(\"userId\", IntegerType(), nullable=True),\n",
        "    StructField(\"movieId\", IntegerType(), nullable=True),\n",
        "    StructField(\"rating\", FloatType(), nullable=True),\n",
        "    StructField(\"timestamp\", IntegerType(), nullable=True)\n",
        "])"
      ],
      "metadata": {
        "id": "AdRP7jXMiF5P"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataFrame using the defined schema\n",
        "ratings_df = spark.createDataFrame(ratings, schema)"
      ],
      "metadata": {
        "id": "JuCKRL_kiL4P"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the DataFrame\n",
        "ratings_df.show(5)"
      ],
      "metadata": {
        "id": "JamymTKNBBEY",
        "outputId": "b9577815-7504-471f-e29d-938a9e90f8d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+------+---------+\n",
            "|userId|movieId|rating|timestamp|\n",
            "+------+-------+------+---------+\n",
            "|     1|      1|   4.0|964982703|\n",
            "|     1|      3|   4.0|964981247|\n",
            "|     1|      6|   4.0|964982224|\n",
            "|     1|     47|   5.0|964983815|\n",
            "|     1|     50|   5.0|964982931|\n",
            "+------+-------+------+---------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Training 80% dan Test 20%\n",
        "training, test = ratings.randomSplit([0.8, 0.2])"
      ],
      "metadata": {
        "id": "cUXDGgQzDH5M"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat Model\n",
        "als = ALS(maxIter=5, regParam=0.01, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\")\n",
        "model = als.fit(ratings_df)  # Melatih model dengan DataFrame yang sesuai\n",
        "\n",
        "# Menyimpan model dengan mengatasi konflik\n",
        "model.write().overwrite().save(\"mymodel\")\n",
        "\n",
        "# Memuat model dari file yang telah disimpan\n",
        "model = ALSModel.load(\"mymodel\")\n",
        "\n",
        "# Prediksi Data\n",
        "predictions = model.transform(test_df)\n",
        "mse = predictions.withColumn(\"diff\", col(\"rating\") - col(\"prediction\")).select((col(\"diff\") ** 2).alias(\"squared_diff\")).filter(~col(\"squared_diff\").isNull()).agg({\"squared_diff\": \"sum\"}).collect()[0][0]\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "\n",
        "predictions.show(10)\n",
        "\n"
      ],
      "metadata": {
        "id": "aAD1RNtVDMFr",
        "outputId": "dd057dd1-5976-4082-ae35-745538704c8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-84-0acd7bde0635>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Prediksi Data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"diff\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rating\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"prediction\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"diff\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"squared_diff\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"squared_diff\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misNull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"squared_diff\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"sum\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mean Squared Error:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'test_df' is not defined"
          ]
        }
      ]
    }
  ]
}